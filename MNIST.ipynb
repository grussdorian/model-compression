{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the neural network\n",
    "model = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.25327837467193604\n",
      "Epoch 2/10, Loss: 0.3734153211116791\n",
      "Epoch 3/10, Loss: 0.25435543060302734\n",
      "Epoch 4/10, Loss: 0.33283886313438416\n",
      "Epoch 5/10, Loss: 0.13344308733940125\n",
      "Epoch 6/10, Loss: 0.06735716760158539\n",
      "Epoch 7/10, Loss: 0.3119622468948364\n",
      "Epoch 8/10, Loss: 0.06611382216215134\n",
      "Epoch 9/10, Loss: 0.09190545976161957\n",
      "Epoch 10/10, Loss: 0.037873003631830215\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the training loss for each epoch\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.58%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0283,  0.0152,  0.0158,  ...,  0.0014, -0.0042, -0.0196],\n",
       "        [-0.0333, -0.0167,  0.0326,  ..., -0.0346, -0.0210, -0.0121],\n",
       "        [-0.0372, -0.0150,  0.0331,  ..., -0.0179, -0.0187, -0.0016],\n",
       "        ...,\n",
       "        [-0.0279,  0.0319,  0.0095,  ...,  0.0096,  0.0053, -0.0107],\n",
       "        [-0.0315, -0.0278, -0.0348,  ...,  0.0171,  0.0220,  0.0150],\n",
       "        [ 0.0266,  0.0271, -0.0241,  ..., -0.0025,  0.0267, -0.0137]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight tensor([[-0.0283,  0.0152,  0.0158,  ...,  0.0014, -0.0042, -0.0196],\n",
      "        [-0.0333, -0.0167,  0.0326,  ..., -0.0346, -0.0210, -0.0121],\n",
      "        [-0.0372, -0.0150,  0.0331,  ..., -0.0179, -0.0187, -0.0016],\n",
      "        ...,\n",
      "        [-0.0279,  0.0319,  0.0095,  ...,  0.0096,  0.0053, -0.0107],\n",
      "        [-0.0315, -0.0278, -0.0348,  ...,  0.0171,  0.0220,  0.0150],\n",
      "        [ 0.0266,  0.0271, -0.0241,  ..., -0.0025,  0.0267, -0.0137]])\n",
      "fc1.bias tensor([-0.0006, -0.0208, -0.0046, -0.0122, -0.0029, -0.0098,  0.0033, -0.0086,\n",
      "        -0.0294,  0.0044,  0.0240,  0.0359, -0.0122,  0.0314, -0.0074,  0.0158,\n",
      "         0.0200,  0.0325, -0.0236,  0.0036, -0.0293,  0.0369,  0.0238,  0.0262,\n",
      "         0.0189, -0.0262,  0.0124,  0.0302,  0.0362, -0.0273,  0.0185, -0.0154,\n",
      "         0.0208,  0.0162, -0.0323,  0.0110, -0.0129,  0.0327, -0.0241,  0.0346,\n",
      "         0.0035, -0.0098,  0.0263, -0.0251, -0.0347, -0.0057,  0.0254,  0.0304,\n",
      "         0.0330,  0.0514,  0.0018, -0.0125, -0.0189,  0.0327,  0.0110,  0.0284,\n",
      "         0.0284, -0.0344, -0.0301, -0.0308, -0.0253,  0.0049, -0.0005,  0.0081,\n",
      "         0.0115, -0.0276, -0.0236,  0.0378,  0.0344, -0.0101, -0.0301,  0.0382,\n",
      "         0.0228, -0.0218,  0.0188,  0.0165, -0.0023, -0.0007, -0.0040, -0.0309,\n",
      "         0.0351,  0.0031,  0.0156,  0.0073, -0.0217,  0.0238,  0.0103, -0.0101,\n",
      "         0.0193,  0.0016,  0.0209,  0.0242,  0.0156,  0.0247,  0.0367,  0.0379,\n",
      "        -0.0381, -0.0018, -0.0120,  0.0129,  0.0144,  0.0577, -0.0302, -0.0042,\n",
      "        -0.0328,  0.0372, -0.0044,  0.0299, -0.0285,  0.0261,  0.0060,  0.0059,\n",
      "        -0.0390,  0.0121,  0.0186,  0.0329, -0.0186, -0.0166, -0.0156,  0.0383,\n",
      "         0.0079, -0.0278,  0.0194,  0.0274, -0.0165, -0.0265,  0.0446, -0.0230])\n",
      "fc2.weight tensor([[ 0.0414, -0.0261, -0.1047,  ..., -0.0067, -0.0776,  0.0300],\n",
      "        [-0.0608, -0.0713, -0.0643,  ..., -0.0636, -0.0119,  0.0882],\n",
      "        [-0.0939, -0.0722, -0.0353,  ..., -0.1271, -0.0356,  0.1354],\n",
      "        ...,\n",
      "        [-0.1013, -0.0372, -0.0242,  ..., -0.0277,  0.1297, -0.0774],\n",
      "        [ 0.0071,  0.0112,  0.0502,  ...,  0.0074,  0.0941, -0.0275],\n",
      "        [-0.0973,  0.1011, -0.0675,  ...,  0.0174,  0.0008, -0.0304]])\n",
      "fc2.bias tensor([ 0.0538,  0.0970, -0.0203,  0.0105, -0.0528,  0.0505, -0.0073, -0.0237,\n",
      "        -0.0851,  0.0042, -0.0701, -0.0664,  0.0491,  0.0952,  0.0574, -0.0695,\n",
      "         0.0922, -0.0440, -0.0184, -0.0739,  0.0134, -0.0474,  0.0237,  0.0510,\n",
      "         0.0478,  0.0785,  0.0087, -0.0637,  0.0723, -0.0207,  0.0600, -0.0011,\n",
      "        -0.0114,  0.0491, -0.0732, -0.0587,  0.0549,  0.0730,  0.0440,  0.0103,\n",
      "         0.0354,  0.0221, -0.0766, -0.0640, -0.0217, -0.0130, -0.0708,  0.0861,\n",
      "         0.0437,  0.0204, -0.0492,  0.0574, -0.0516, -0.0650, -0.0177, -0.0799,\n",
      "         0.0422, -0.0017, -0.0704,  0.0172,  0.0484,  0.0804, -0.0114, -0.0342])\n",
      "fc3.weight tensor([[ 8.8243e-02,  2.2734e-01,  2.1226e-01,  1.3529e-02,  3.8036e-01,\n",
      "          1.0022e-01,  6.2492e-02,  4.7561e-02,  1.4824e-02, -4.1393e-02,\n",
      "          4.7523e-02, -4.4221e-02, -6.1745e-02,  1.2023e-02, -9.4801e-02,\n",
      "         -5.3768e-02, -5.5299e-03,  2.0413e-01, -2.2976e-01,  6.2024e-02,\n",
      "         -1.1040e-01,  2.0901e-01, -7.3811e-02,  4.0163e-02, -2.6807e-02,\n",
      "         -3.9969e-03, -7.6832e-02, -1.4424e-01,  2.6791e-02, -9.6054e-02,\n",
      "         -6.3720e-02,  1.3652e-03,  1.8829e-01,  8.6502e-02, -9.0622e-02,\n",
      "          7.4666e-02, -2.5451e-01, -3.4219e-01, -8.8134e-03, -6.3788e-02,\n",
      "         -9.1113e-02,  3.6840e-01, -5.1104e-02, -1.4714e-01, -2.5329e-01,\n",
      "          1.5817e-01, -7.7343e-02, -5.6825e-02, -1.9259e-02,  5.4081e-03,\n",
      "          1.3007e-01,  1.7402e-01,  2.8461e-01, -1.3559e-01,  5.4271e-02,\n",
      "         -9.7208e-02, -2.8342e-02,  1.9931e-01, -1.5855e-01, -8.9112e-02,\n",
      "         -2.6139e-01, -5.4112e-02, -2.1794e-02, -3.0172e-02],\n",
      "        [-2.5702e-01, -2.2196e-01, -2.5837e-01,  1.5704e-01,  8.6648e-02,\n",
      "          1.6077e-02,  1.0023e-02, -7.3632e-02,  7.6687e-02,  6.2641e-02,\n",
      "         -6.0466e-02, -1.6555e-01,  2.9633e-02,  3.2316e-01, -1.0740e-01,\n",
      "          4.8088e-02,  1.7303e-01, -1.0618e-01,  1.9364e-01, -5.4072e-02,\n",
      "          4.9086e-02, -2.2443e-01, -3.1025e-01,  4.4530e-02, -1.7332e-01,\n",
      "         -1.8039e-01, -9.8466e-02, -1.6601e-01, -1.8526e-01,  2.3185e-01,\n",
      "         -6.6660e-02,  4.6825e-02,  7.6234e-02, -1.2643e-01,  1.3825e-01,\n",
      "          7.6750e-02,  1.5433e-01,  1.6641e-01,  1.8820e-01, -1.7002e-01,\n",
      "          5.6740e-02, -5.4070e-02,  2.4651e-02,  4.0166e-01, -1.6335e-01,\n",
      "         -5.2158e-02, -7.7025e-02,  6.6854e-02,  2.6822e-01, -5.9351e-02,\n",
      "          7.2292e-02, -3.9197e-02,  1.1814e-01,  1.3502e-01,  1.8694e-01,\n",
      "         -8.4643e-02,  2.4977e-01, -2.1155e-01, -4.4612e-02, -8.1769e-02,\n",
      "          5.3365e-02, -9.3270e-02,  2.2419e-01, -3.8924e-02],\n",
      "        [-7.9131e-02, -2.1413e-01, -3.2929e-02,  2.3264e-01,  1.6330e-01,\n",
      "          3.9961e-01,  1.0538e-01, -7.1555e-03, -1.3086e-02, -5.8231e-02,\n",
      "          4.4699e-03,  1.6927e-01,  1.3239e-01, -3.2103e-01, -8.5141e-02,\n",
      "         -5.1414e-02, -3.3045e-02,  3.8426e-01,  1.5155e-01,  1.4924e-01,\n",
      "          9.1428e-02, -1.4291e-01, -7.1877e-02,  6.0038e-02,  3.7340e-01,\n",
      "          2.2698e-01, -2.9308e-02,  8.3269e-02, -2.2629e-01, -1.9855e-01,\n",
      "         -2.1613e-01, -2.7233e-01, -1.4155e-01, -1.8207e-02,  1.0643e-02,\n",
      "         -2.0670e-01, -1.5725e-01,  5.4459e-02,  1.1442e-01, -7.6154e-02,\n",
      "          4.4057e-02, -2.0816e-01,  1.2974e-01, -2.1157e-01,  2.7793e-01,\n",
      "         -2.1734e-01, -1.0158e-01,  4.1292e-03, -1.0665e-02,  6.8412e-02,\n",
      "          6.2693e-02, -1.7457e-01, -2.6191e-02,  1.6306e-01,  1.5846e-01,\n",
      "         -9.7749e-02,  6.9596e-02,  2.5256e-01,  2.9378e-01,  2.9318e-01,\n",
      "         -2.5804e-01, -1.8703e-01, -2.4045e-01,  2.8105e-02],\n",
      "        [ 2.3212e-01,  3.9555e-02, -2.2776e-01, -5.1201e-02, -1.1242e-03,\n",
      "          2.0023e-01,  9.6777e-02, -1.1752e-01,  5.8565e-02,  8.3544e-02,\n",
      "          3.1509e-03,  5.7298e-02,  3.6470e-02,  3.0153e-01,  2.5496e-02,\n",
      "         -2.0734e-01, -4.6654e-02, -2.5236e-01,  3.3461e-01,  5.6501e-02,\n",
      "         -4.3388e-01, -3.0686e-01,  1.2135e-01,  5.7978e-02,  2.1714e-01,\n",
      "         -1.3687e-02,  1.3969e-01,  1.9684e-01,  5.3750e-02, -6.7292e-02,\n",
      "          1.1781e-01, -3.8554e-01, -3.1542e-02, -1.6755e-01,  6.1760e-02,\n",
      "         -3.3490e-01, -3.2066e-02,  1.5127e-01, -1.6938e-01, -8.0202e-02,\n",
      "          4.8235e-02, -5.4149e-02,  3.6988e-01,  8.1685e-02, -4.0834e-02,\n",
      "         -1.1554e-02,  7.3491e-02,  1.0173e-01,  1.4556e-01,  3.4996e-02,\n",
      "         -2.3527e-02, -9.6273e-02,  7.3251e-03, -2.3212e-01,  2.2451e-02,\n",
      "         -1.6508e-02, -2.3855e-01,  2.1223e-01, -1.5502e-01,  4.5061e-02,\n",
      "          3.5558e-01,  1.9012e-02, -1.5785e-01,  2.4899e-01],\n",
      "        [ 1.8427e-01, -4.1265e-02, -2.5734e-01, -1.7244e-01, -2.8713e-01,\n",
      "          2.4621e-06, -5.4990e-02,  1.2292e-01, -2.8507e-02, -9.5950e-02,\n",
      "          9.6432e-02,  2.4701e-01, -7.0772e-03, -1.3807e-01,  7.3809e-02,\n",
      "          3.2978e-01, -2.3966e-01,  1.0981e-01,  5.1006e-02, -1.4026e-01,\n",
      "          2.1486e-01,  2.8074e-02,  2.5694e-01, -1.1225e-01, -3.6284e-01,\n",
      "          1.1762e-01,  2.7497e-01, -1.1271e-01,  6.0260e-02,  1.9321e-01,\n",
      "          2.4942e-01,  9.1896e-02,  1.0569e-01,  3.2642e-03, -9.5078e-02,\n",
      "         -1.0854e-01, -1.2023e-01,  1.6714e-01, -2.1198e-01, -7.4411e-02,\n",
      "          9.0686e-02,  1.4785e-01, -8.5209e-02,  1.2011e-01,  1.8409e-03,\n",
      "          1.4853e-01,  1.6064e-01, -3.7564e-02, -3.0415e-01, -1.2893e-01,\n",
      "          1.4854e-01,  1.9175e-01, -2.4645e-02,  1.1806e-01, -9.4550e-03,\n",
      "         -1.9387e-02, -9.3669e-02, -3.5116e-01,  3.3857e-01, -1.9975e-01,\n",
      "         -1.7038e-02, -1.7778e-02,  1.2030e-02, -3.8455e-01],\n",
      "        [ 2.8654e-01,  7.9489e-02,  2.5866e-01, -1.5614e-02, -3.5849e-02,\n",
      "         -4.0132e-01,  1.0209e-01, -1.3346e-01,  1.3919e-02,  1.1190e-01,\n",
      "         -1.2480e-02,  6.6545e-02, -3.8490e-03,  3.0310e-01,  2.0074e-01,\n",
      "         -1.6445e-01,  3.0941e-01,  4.0991e-02,  1.2132e-01, -1.4192e-01,\n",
      "          8.7605e-02,  1.0900e-01,  5.2347e-02,  1.7453e-01,  2.1568e-02,\n",
      "          1.1387e-01, -1.1830e-01,  1.8159e-01,  2.3325e-01,  8.7746e-02,\n",
      "          2.1921e-01,  5.5382e-02, -1.8351e-01,  8.9547e-02, -1.0839e-01,\n",
      "          3.4212e-01,  1.2568e-01, -1.3703e-01,  8.8255e-02, -1.0023e-01,\n",
      "          1.8428e-01, -4.1796e-01, -8.7762e-02, -3.3754e-01,  1.0404e-02,\n",
      "          1.5355e-01,  4.1264e-01,  1.0259e-01, -1.9667e-01,  1.3381e-01,\n",
      "         -1.9524e-02, -3.4489e-01, -2.4391e-01, -2.0259e-01, -2.9722e-01,\n",
      "          5.6470e-02, -5.7394e-03,  4.9703e-01, -9.1371e-02, -3.1886e-02,\n",
      "          2.3388e-01, -2.4107e-01,  2.1999e-01, -8.2337e-04],\n",
      "        [-8.1269e-02,  1.7279e-01, -1.3874e-01, -1.6897e-02, -4.5135e-02,\n",
      "          9.1146e-02,  2.3552e-02, -6.0558e-02, -5.2507e-02,  1.2088e-01,\n",
      "          5.0772e-02,  1.8728e-01,  1.1920e-01, -1.6792e-01, -1.1504e-01,\n",
      "         -1.8824e-01,  7.8047e-02,  3.5056e-02, -3.4023e-01,  4.3948e-02,\n",
      "          3.7438e-01, -7.6007e-02,  3.9169e-02, -5.8566e-02,  1.0712e-01,\n",
      "         -3.0859e-01,  3.7228e-02,  1.9717e-01, -4.1113e-02,  3.6955e-01,\n",
      "          1.6107e-01,  3.5552e-01,  7.6773e-02, -1.0571e-01,  1.7070e-01,\n",
      "          1.0332e-01,  5.9230e-02, -2.9473e-01, -5.7574e-02, -2.0106e-01,\n",
      "          1.2409e-01,  1.9726e-01, -2.1461e-01, -2.0141e-01, -1.7227e-01,\n",
      "          1.5361e-01, -1.4090e-01,  5.2361e-02,  7.9282e-02, -2.0917e-02,\n",
      "          8.8668e-02,  7.8824e-02, -1.4600e-01,  4.2218e-01,  3.3720e-02,\n",
      "          8.1334e-02, -7.5688e-02,  2.0155e-01, -1.1804e-01, -1.1608e-01,\n",
      "         -1.6380e-01, -3.4297e-01,  1.3240e-01,  5.4681e-02],\n",
      "        [-5.1227e-02,  1.7511e-02, -7.4974e-02,  1.6165e-01, -3.5819e-02,\n",
      "         -5.0833e-02, -9.2920e-02,  4.5396e-02,  1.0457e-01, -6.4049e-02,\n",
      "         -4.1251e-02,  1.7715e-04, -1.2956e-01, -3.1334e-01,  1.1350e-01,\n",
      "          1.4301e-01, -6.9328e-03,  9.7863e-02,  2.9523e-01, -1.8197e-01,\n",
      "         -1.7345e-01,  2.0181e-01, -1.1775e-01,  4.5553e-02,  3.2767e-01,\n",
      "          9.1512e-02, -2.8435e-01,  1.0374e-01, -2.1674e-01,  1.2411e-03,\n",
      "         -1.7424e-01, -1.0812e-01,  1.2550e-01, -1.1582e-02, -8.0187e-02,\n",
      "         -1.2979e-01,  2.3128e-01, -3.4183e-03,  6.5417e-02,  4.5565e-01,\n",
      "          1.1988e-01, -1.1232e-01, -2.6876e-01, -6.7306e-02, -1.4519e-02,\n",
      "         -9.4013e-02, -3.4925e-01, -1.0490e-01, -2.6620e-01,  2.1079e-02,\n",
      "         -1.5904e-01,  8.3531e-02, -1.1161e-01, -1.8240e-01,  1.0388e-01,\n",
      "         -4.3305e-02, -1.0674e-01, -1.8152e-01, -3.0494e-01, -7.4024e-02,\n",
      "          3.3025e-02,  4.9212e-01,  4.8755e-02,  1.0144e-01],\n",
      "        [ 1.4572e-01,  2.7696e-01,  1.8427e-01, -6.8673e-02, -2.1520e-01,\n",
      "          2.3895e-01,  6.9681e-02,  6.3455e-02, -1.1516e-01,  1.0182e-01,\n",
      "         -5.1455e-02, -1.7672e-01,  4.4843e-02, -1.3104e-01, -1.9960e-01,\n",
      "         -3.7759e-01,  7.7693e-02,  5.4381e-02, -2.4122e-02,  8.1217e-02,\n",
      "          1.9560e-01,  7.0566e-02,  3.6099e-01, -1.2925e-01, -2.9090e-01,\n",
      "         -2.0953e-01, -2.4089e-01, -1.5882e-01,  2.2176e-01, -2.6515e-01,\n",
      "         -9.6165e-02,  2.9575e-01, -4.8969e-02, -1.9763e-01, -4.6899e-02,\n",
      "          1.0659e-01, -1.5003e-01,  1.7819e-01,  2.2919e-01, -2.4029e-01,\n",
      "         -2.3644e-02,  4.4512e-02,  2.7334e-01, -4.0418e-02,  3.4264e-01,\n",
      "          1.9298e-02,  1.8536e-01,  6.3494e-02,  2.9038e-01,  1.6220e-02,\n",
      "         -1.2529e-01, -2.0326e-02,  1.7057e-02, -9.8886e-02, -2.0650e-01,\n",
      "          8.4879e-02,  1.3268e-01, -3.7329e-01,  5.6089e-02,  1.4941e-02,\n",
      "          4.6878e-02,  1.1152e-01, -2.4988e-02, -1.0908e-01],\n",
      "        [-1.0510e-01,  3.4409e-02, -1.3583e-01, -1.5857e-01, -2.0037e-01,\n",
      "         -2.4763e-01,  9.6211e-03,  1.7190e-02,  1.6980e-02, -4.3960e-03,\n",
      "          1.0923e-01, -1.6180e-01, -5.0595e-02,  1.7582e-01,  2.0269e-01,\n",
      "          7.8918e-02,  1.0303e-01, -2.9210e-01, -3.1993e-01,  6.5940e-02,\n",
      "         -8.5850e-02,  1.5747e-01, -1.8854e-01, -1.2137e-01, -1.4310e-01,\n",
      "          9.5809e-02,  2.8100e-01, -3.0876e-01,  1.3067e-01, -4.2885e-01,\n",
      "          1.1501e-03,  1.4435e-01,  1.5431e-01, -1.8834e-01,  1.0321e-01,\n",
      "          1.7062e-01, -1.4862e-01,  2.0143e-01, -3.6477e-01,  9.7932e-02,\n",
      "         -1.3669e-01,  2.5528e-01, -2.0143e-02,  2.1601e-01,  1.3261e-01,\n",
      "          1.8715e-02,  2.7822e-01,  2.1548e-02, -6.0415e-02, -7.8023e-02,\n",
      "         -1.0695e-01,  2.6301e-01,  7.0819e-02, -2.8726e-01,  4.4919e-02,\n",
      "          4.5006e-02,  3.0710e-02, -1.8518e-02,  9.5747e-02, -3.2692e-02,\n",
      "          1.2844e-01,  4.3018e-01,  5.1763e-02,  1.8367e-01]])\n",
      "fc3.bias tensor([-0.0664,  0.0333, -0.0336,  0.0833,  0.0552,  0.0830, -0.0819,  0.1298,\n",
      "        -0.1284, -0.0553])\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is your PyTorch neural network model\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_copy = Net()  # Assuming 'Net' is the class definition of your neural network\n",
    "model_copy.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_fc1 = model_copy.fc1.weight.data.clone()\n",
    "biasess_fc1 = model_copy.fc1.bias.data.clone()\n",
    "weights_fc2 = model_copy.fc2.weight.data.clone()\n",
    "biasess_fc2 = model_copy.fc2.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 784]) torch.Size([64, 128])\n",
      "torch.Size([128]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(weights_fc1.shape, weights_fc2.shape)\n",
    "print(biasess_fc1.shape, biasess_fc2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy.fc1.weight.data = weights_fc1\n",
    "model_copy.fc1.bias.data = biasess_fc1\n",
    "model_copy.fc2.weight.data = weights_fc2\n",
    "model_copy.fc2.bias.data = biasess_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 784])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_fc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0137)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_fc1[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy model_copy: 96.58%\n",
      "Test Accuracy model: 96.58%\n"
     ]
    }
   ],
   "source": [
    "model_copy.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model_copy(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f'Test Accuracy model_copy: {accuracy}%')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f'Test Accuracy model: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_copy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the neural network\n",
    "model2 = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.4088421165943146\n",
      "Epoch 2/10, Loss: 0.11871203780174255\n",
      "Epoch 3/10, Loss: 0.4515531659126282\n",
      "Epoch 4/10, Loss: 0.5418092012405396\n",
      "Epoch 5/10, Loss: 0.09428226202726364\n",
      "Epoch 6/10, Loss: 0.14835457503795624\n",
      "Epoch 7/10, Loss: 0.3167040944099426\n",
      "Epoch 8/10, Loss: 0.017398031428456306\n",
      "Epoch 9/10, Loss: 0.04062199592590332\n",
      "Epoch 10/10, Loss: 0.16353219747543335\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model2(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the training loss for each epoch\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.17%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model2.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model2(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
